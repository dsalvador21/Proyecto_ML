{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de88f0ca",
   "metadata": {},
   "source": [
    "## Preparación para el Modelado\n",
    "\n",
    "Con base en la exploración inicial del dataset de características derivadas del intervalo RR, se tomaron las siguientes decisiones para mejorar el rendimiento del modelo de clasificación:\n",
    "\n",
    "### 1. Balanceo de Clases con SMOTE\n",
    "Se observó un fuerte desbalance entre las clases: la mayoría de las muestras corresponden a ritmo normal (N) y solo unas pocas a fibrilación auricular (A). Para mitigar este desequilibrio y evitar que el modelo favorezca la clase mayoritaria, se aplicará la técnica **SMOTE (Synthetic Minority Over-sampling Technique)**, generando ejemplos sintéticos de la clase minoritaria.\n",
    "\n",
    "### 2. Eliminación de Outliers\n",
    "Se detectaron valores extremos en las variables `mean_rr`, `std_rr` y `kurt_rr`, con máximos considerablemente alejados del rango intercuartílico. Estos outliers pueden afectar negativamente el proceso de entrenamiento. Se utilizará la técnica del **IQR (Interquartile Range)** para identificar y eliminar registros atípicos por variable.\n",
    "\n",
    "### 3. Ajuste de Hiperparámetros\n",
    "Una vez establecido el modelo base (Random Forest), se realizará una búsqueda sistemática de hiperparámetros utilizando **GridSearchCV**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f15eef",
   "metadata": {},
   "source": [
    "## Justificación del uso de Random Forest\n",
    "\n",
    "Random Forest es una opción adecuada para este problema porque puede manejar relaciones no lineales entre las variables estadísticas del intervalo RR sin necesidad de preprocesamiento complejo. Es resistente al ruido y a valores atípicos, lo que es útil en datos fisiológicos. Además, al combinar múltiples árboles, reduce el riesgo de sobreajuste y permite estimar la importancia de las variables, lo cual es útil para interpretar el modelo y guiar posibles mejoras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c98fd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 5774 registros\n",
      "Limpios con feature-engine: 5226 registros\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.45      0.80      0.58       133\n",
      "           N       0.97      0.86      0.91       913\n",
      "\n",
      "    accuracy                           0.85      1046\n",
      "   macro avg       0.71      0.83      0.74      1046\n",
      "weighted avg       0.90      0.85      0.87      1046\n",
      "\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from feature_engine.outliers import OutlierTrimmer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, ConfusionMatrixDisplay\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(\"../data/ecg_rr_features_curado.csv\")\n",
    "\n",
    "# Columnas numéricas\n",
    "columnas = [\"mean_rr\", \"std_rr\", \"skew_rr\", \"kurt_rr\"]\n",
    "\n",
    "# Separar por clase\n",
    "df_n = df[df['label'] == 'N'].copy()\n",
    "df_a = df[df['label'] == 'A'].copy()\n",
    "\n",
    "# Mostrar número de registros originales\n",
    "print(f\"Original: {len(df)} registros\")\n",
    "\n",
    "# Crear el trimmer para cada clase\n",
    "trimmer_n = OutlierTrimmer(capping_method='iqr', tail='both', fold=2, variables=columnas)\n",
    "df_n_clean = trimmer_n.fit_transform(df_n)\n",
    "\n",
    "trimmer_a = OutlierTrimmer(capping_method='iqr', tail='both', fold=2, variables=columnas)\n",
    "df_a_clean = trimmer_a.fit_transform(df_a)\n",
    "\n",
    "# Unir las clases limpias\n",
    "df = pd.concat([df_n_clean, df_a_clean], ignore_index=True)\n",
    "\n",
    "# Mostrar número de registros después de limpieza\n",
    "print(f\"Limpios con feature-engine: {len(df)} registros\")\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = df.drop(columns=[\"record\", \"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# División en conjuntos de entrenamiento y prueba, y aplicación de SMOTE\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train_smote, y_train_smote)\n",
    "clf = grid.best_estimator_\n",
    "\n",
    "# Curva de aprendizaje\n",
    "train_sizes, tr_scores, val_scores = learning_curve(\n",
    "    clf, X_train_smote, y_train_smote,\n",
    "    cv=5, scoring=\"f1_weighted\", n_jobs=-1\n",
    ")\n",
    "plt.plot(train_sizes, tr_scores.mean(1), label=\"Entrenamiento\")\n",
    "plt.plot(train_sizes, val_scores.mean(1), label=\"Validación\")\n",
    "plt.xlabel(\"# muestras de entrenamiento\")\n",
    "plt.ylabel(\"F1 ponderado\")\n",
    "plt.title(\"Curva de Aprendizaje – Random Forest\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Importancia de variables\n",
    "importances = clf.feature_importances_\n",
    "feat_names = X.columns\n",
    "idx = np.argsort(importances)[::-1][:15]\n",
    "\n",
    "plt.barh(range(len(idx)), importances[idx][::-1])\n",
    "plt.yticks(range(len(idx)), feat_names[idx][::-1])\n",
    "plt.xlabel(\"Importancia media\")\n",
    "plt.title(\"Top Features – Random Forest\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluación\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"\\nMejores hiperparámetros encontrados:\")\n",
    "print(grid.best_params_)\n",
    "print(\"\\nReporte por clase:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "plt.title(\"Matriz de Confusión\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256b30be",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo: Análisis y Mejoras\n",
    "\n",
    "### Descripción de métricas y relevancia médica\n",
    "\n",
    "- **Accuracy (Exactitud):**  \n",
    "  89%. Mide el porcentaje total de predicciones correctas. Es útil como visión general, pero puede ser engañosa en datasets desbalanceados como este (801 N vs. 130 A).\n",
    "\n",
    "- **Precision (Clase A: 0.57):**  \n",
    "  Solo el 57% de los casos que el modelo predijo como AFib eran realmente AFib.  \n",
    "  En medicina, esto implica que **hay falsos positivos**, pero no es lo más grave clínicamente.\n",
    "\n",
    "- **Recall (Clase A: 0.76):**  \n",
    "  El 76% de los verdaderos casos de AFib fueron correctamente detectados.  \n",
    "  Esta métrica es **clave en este contexto médico**, ya que no detectar AFib puede tener consecuencias graves. Es preferible equivocarse de más (falsos positivos) que dejar pasar un caso real.\n",
    "\n",
    "- **F1-score (Clase A: 0.65):**  \n",
    "  Equilibra precisión y recall. El valor indica que el modelo aún tiene margen de mejora, especialmente para reducir los falsos negativos **sin sacrificar demasiado la precisión**.\n",
    "\n",
    "- **Matriz de confusión:**  \n",
    "  - **Falsos negativos:** 31 casos de AFib fueron clasificados como normales.\n",
    "  - **Falsos positivos:** 74 casos normales fueron clasificados como AFib.\n",
    "  Esto indica un sesgo levemente conservador, lo cual **no es tan negativo médicamente** si se prioriza la detección temprana.\n",
    "\n",
    "---\n",
    "\n",
    "### Cosas positivas\n",
    "\n",
    "- Buen **recall para la clase A (0.76)**, lo cual es fundamental.\n",
    "- Alto **recall y precisión en la clase N**, lo que demuestra robustez en ritmos normales.\n",
    "- La **curva de aprendizaje** muestra que el modelo **aún mejora con más datos**, y que no está sobreajustado (la curva de validación sigue subiendo).\n",
    "- La distribución de **importancia de variables** es razonable: `skew_rr` y `std_rr` destacan, indicando que las irregularidades en el ritmo tienen peso en el diagnóstico.\n",
    "\n",
    "---\n",
    "\n",
    "### Propuestas de mejora\n",
    "\n",
    "1. **Aumentar recall de clase A (menos falsos negativos).**\n",
    "\n",
    "2. **Reducir falsos positivos (mejorar precisión).**\n",
    "\n",
    "3. **Mejorar input del modelo:**\n",
    "   - Crear nuevas variables como:\n",
    "     - `cv_rr = std_rr / mean_rr` (coeficiente de variación)\n",
    "     - `iqr_rr`, `range_rr`, `median_rr`\n",
    "   - Realizar **transformaciones logarítmicas o normalizaciones robustas** en `kurt_rr` y `skew_rr`, que tienden a tener outliers fuertes.\n",
    "\n",
    "4. **Simplificación del modelo:**\n",
    "   - Aunque `skew_rr` lidera en importancia, `kurt_rr` es la menos informativa. Se puede intentar entrenar un modelo con solo las 2 o 3 variables más relevantes y ver si se mantiene el rendimiento.\n",
    "\n",
    "5. **Evaluación en otras métricas clínicas:**\n",
    "   - Usar **curvas ROC** o **curvas precision-recall ajustadas** para seleccionar el mejor punto de operación del modelo según necesidades clínicas reales.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "El modelo logra un balance sólido entre precisión y sensibilidad, especialmente con un **buen recall en fibrilación auricular**, que es el objetivo principal. Todavía hay margen para reducir los errores (falsos negativos y positivos), ya sea mediante ajuste de umbrales, mejoras de input o modelos más especializados. El modelo es funcional y clínicamente útil, pero puede volverse aún más fiable con refinamientos.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
